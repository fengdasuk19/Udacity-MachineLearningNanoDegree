
/-------------------------
| Training trial 1
\-------------------------

Environment.reset(): Trial set up with start = (3, 7), destination = (8, 6), deadline = 20
Simulating trial. . . 
epsilon = 1.0000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
learning, learn new
zeroAction: ['forward', 'left', 'right', None]
in random choose:
At last we choose: forward
Environment.act() [POST]: location: (3, 7), heading: (0, 1), action: forward, reward: -39.3277089916
Environment.act(): Step data: {'inputs': {'light': 'red', 'oncoming': None, 'right': 'right', 'left': 'forward'}, 'violation': 4, 'light': 'red', 'state': ('right', 'red', None, 'forward', 'right'), 'deadline': 20, 't': 0, 'action': 'forward', 'reward': -39.32770899157687, 'waypoint': 'right'}
Agent previous state: ('right', 'red', None, 'forward', 'right')
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.33)
95% of time remaining to reach destination.

Simulation ended. . . 
